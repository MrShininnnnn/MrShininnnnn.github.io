---
---

@article{wang2023interactive, 
    selected=true, 
    abbr={arXiv}, 
    arxiv={2305.13246}, 
    url={https://arxiv.org/abs/2305.13246}, 
    pdf={https://arxiv.org/pdf/2305.13246.pdf}, 
    code={https://github.com/InteractiveNLP-Team/awesome-InteractiveNLP-papers}, 
    title={Interactive natural language processing}, 
    author={Wang, Zekun and Zhang, Ge and Yang, Kexin and Shi, Ning and Zhou, Wangchunshu and Hao, Shaochun and Xiong, Guangzheng and Li, Yizhi and Sim, Mong Yuan and Chen, Xiuying and others}, 
    journal={arXiv preprint arXiv:2305.13246}, 
    year={2023}, 
    abstract="Interactive Natural Language Processing (iNLP) has emerged as a novel paradigm within the field of NLP, aimed at addressing limitations in existing frameworks while aligning with the ultimate goals of artificial intelligence. This paradigm considers language models as agents capable of observing, acting, and receiving feedback iteratively from external entities. Specifically, language models in this context can: (1) interact with humans for better understanding and addressing user needs, personalizing responses, aligning with human values, and improving the overall user experience; (2) interact with knowledge bases for enriching language representations with factual knowledge, enhancing the contextual relevance of responses, and dynamically leveraging external information to generate more accurate and informed responses; (3) interact with models and tools for effectively decomposing and addressing complex tasks, leveraging specialized expertise for specific subtasks, and fostering the simulation of social behaviors; and (4) interact with environments for learning grounded representations of language, and effectively tackling embodied tasks such as reasoning, planning, and decision-making in response to environmental observations. This paper offers a comprehensive survey of iNLP, starting by proposing a unified definition and framework of the concept. We then provide a systematic classification of iNLP, dissecting its various components, including interactive objects, interaction interfaces, and interaction methods. We proceed to delve into the evaluation methodologies used in the field, explore its diverse applications, scrutinize its ethical and safety issues, and discuss prospective research directions. This survey serves as an entry point for researchers who are interested in this rapidly evolving area and offers a broad view of the current landscape and future trajectory of iNLP."
}

@article{zhang2023don, 
    selected=false, 
    abbr={arXiv}, 
    arxiv={2305.16339}, 
    url={https://arxiv.org/abs/2305.16339}, 
    pdf={https://arxiv.org/pdf/2305.16339.pdf}, 
    title={Don't Trust GPT When Your Question Is Not In English}, 
    author={Zhang, Xiang and Li, Senyu and Hauer, Bradley and Shi, Ning and Kondrak, Grzegorz}, 
    journal={arXiv preprint arXiv:2305.16339}, 
    year={2023}, 
    abstract="Large Language Models (LLMs) have demonstrated exceptional natural language understanding abilities and have excelled in a variety of natural language processing (NLP)tasks in recent years. Despite the fact that most LLMs are trained predominantly in English, multiple studies have demonstrated their comparative performance in many other languages. However, fundamental questions persist regarding how LLMs acquire their multi-lingual abilities and how performance varies across different languages. These inquiries are crucial for the study of LLMs since users and researchers often come from diverse language backgrounds, potentially influencing their utilization and interpretation of LLMs' results. In this work, we propose a systematic way of qualifying the performance disparities of LLMs under multilingual settings. We investigate the phenomenon of across-language generalizations in LLMs, wherein insufficient multi-lingual training data leads to advanced multi-lingual capabilities. To accomplish this, we employ a novel back-translation-based prompting method. The results show that GPT exhibits highly translating-like behaviour in multilingual settings."
}

@inproceedings{chen-etal-2023-adversarial,
    selected=false, 
    abbr={ACL Findings}, 
    arxiv={2305.18503}, 
    pdf={https://aclanthology.org/2023.findings-acl.611.pdf}, 
    code={https://github.com/thunlp/RobTest}, 
    title = "From Adversarial Arms Race to Model-centric Evaluation: Motivating a Unified Automatic Robustness Evaluation Framework",
    author = "Chen, Yangyi  and
      Gao, Hongcheng  and
      Cui, Ganqu  and
      Yuan, Lifan  and
      Kong, Dehan  and
      Wu, Hanlu  and
      Shi, Ning  and
      Yuan, Bo  and
      Huang, Longtao  and
      Xue, Hui  and
      Liu, Zhiyuan  and
      Sun, Maosong  and
      Ji, Heng",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.611",
    pages = "9607--9632",
    abstract = "Textual adversarial attacks can discover models{'} weaknesses by adding semantic-preserved but misleading perturbations to the inputs. The long-lasting adversarial attack-and-defense arms race in Natural Language Processing (NLP) is algorithm-centric, providing valuable techniques for automatic robustness evaluation. However, the existing practice of robustness evaluation may exhibit issues of incomprehensive evaluation, impractical evaluation protocol, and invalid adversarial samples. In this paper, we aim to set up a unified automatic robustness evaluation framework, shifting towards model-centric evaluation to further exploit the advantages of adversarial attacks. To address the above challenges, we first determine robustness evaluation dimensions based on model capabilities and specify the reasonable algorithm to generate adversarial samples for each dimension. Then we establish the evaluation protocol, including evaluation settings and metrics, under realistic demands. Finally, we use the perturbation degree of adversarial samples to control the sample validity. We implement a toolkit \textbf{RobTest} that realizes our automatic robustness evaluation framework. In our experiments, we conduct a robustness evaluation of RoBERTa models to demonstrate the effectiveness of our evaluation framework, and further show the rationality of each component in the framework.",
}

@inproceedings{ogezi-etal-2023-ualberta,
    selected=false, 
    abbr={SemEval}, 
    arxiv={2306.14067}, 
    pdf={https://aclanthology.org/2023.semeval-1.281.pdf}, 
    code={https://github.com/UAlberta-NLP/v-wsd}, 
    poster={UAlberta\ at\ SemEval\ 2023\ Task\ 1\ Context\ Augmentation\ and\ Translation\ for\ Visual\ WSD.pdf}, 
    slides={UAlberta\ at\ SemEval\ 2023\ Task\ 1\ Context\ Augmentation\ and\ Translation\ for\ Visual\ WSD.pdf}, 
    title = "{UA}lberta at {S}em{E}val-2023 Task 1: Context Augmentation and Translation for Multilingual Visual Word Sense Disambiguation",
    author = "Ogezi, Michael  and
      Hauer, Bradley  and
      Omarov, Talgat  and
      Shi, Ning  and
      Kondrak, Grzegorz",
    booktitle = "Proceedings of the The 17th International Workshop on Semantic Evaluation (SemEval-2023)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.semeval-1.281",
    pages = "2043--2051",
    abstract = "We describe the systems of the University of Alberta team for the SemEval-2023 Visual Word Sense Disambiguation (V-WSD) Task. We present a novel algorithm that leverages glosses retrieved from BabelNet, in combination with text and image encoders. Furthermore, we compare language-specific encoders against the application of English encoders to translated texts. As the contexts given in the task datasets are extremely short, we also experiment with augmenting these contexts with descriptions generated by a language model. This yields substantial improvements in accuracy. We describe and evaluate additional V-WSD methods which use image generation and text-conditioned image segmentation. Some of our experimental results exceed those of our official submissions on the test set. Our code is publicly available at https://github.com/UAlberta-NLP/v-wsd."
}

@inproceedings{zhang-etal-2023-bridging,
    selected=false, 
    abbr={EACL}, 
    url={https://aclanthology.org/2023.eacl-main.205/}, 
    pdf={https://aclanthology.org/2023.eacl-main.205.pdf}, 
    code={https://github.com/senseAlign/BabelNet_2_HowNet}, 
    poster={Bridging\ the\ Gap\ Between\ BabelNet\ and\ HowNet\ Unsupervised\ Sense\ Alignment\ and\ Sememe\ Prediction.pdf}, 
    slides={Bridging\ the\ Gap\ Between\ BabelNet\ and\ HowNet\ Unsupervised\ Sense\ Alignment\ and\ Sememe\ Prediction.pdf}, 
    title = "Bridging the Gap Between {B}abel{N}et and {H}ow{N}et: Unsupervised Sense Alignment and Sememe Prediction",
    author = "Zhang, Xiang  and
      Shi, Ning  and
      Hauer, Bradley  and
      Kondrak, Grzegorz",
    booktitle = "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics",
    month = may,
    year = "2023",
    address = "Dubrovnik, Croatia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.eacl-main.205",
    pages = "2789--2798",
    abstract = "As the minimum semantic units of natural languages, sememes can provide precise representations of concepts. Despite the widespread utilization of lexical resources for semantic tasks, use of sememes is limited by a lack of available sememe knowledge bases. Recent efforts have been made to connect BabelNet with HowNet by automating sememe prediction. However, these methods depend on large manually annotated datasets. We propose to use sense alignment via a novel unsupervised and explainable method. Our method consists of four stages, each relaxing predefined constraints until a complete alignment of BabelNet synsets to HowNet senses is achieved. Experimental results demonstrate the superiority of our unsupervised method over previous supervised ones by an improvement of 12{\%} overall F1 score, setting a new state of the art. Our work is grounded in an interpretable propagation of sememe information between lexical resources, and may benefit downstream applications which can incorporate sememe information.",
}

@inproceedings{shi-etal-2022-revisit,
    selected=true, 
    abbr={BlackboxNLP}, 
    arxiv={2003.06658}, 
    url={https://aclanthology.org/2022.blackboxnlp-1.6/}, 
    pdf={https://aclanthology.org/2022.blackboxnlp-1.6.pdf}, 
    code={https://github.com/ShiningLab/Systematic-Generalization-via-Meaningful-Learning}, 
    poster={Revisit\ Systematic\ Generalization\ via\ Meaningful\ Learning.pdf}, 
    title = "Revisit Systematic Generalization via Meaningful Learning",
    author = "Shi, Ning  and
      Wang, Boxin  and
      Wang, Wei  and
      Liu, Xiangyu  and
      Lin, Zhouhan",
    booktitle = "Proceedings of the Fifth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates (Hybrid)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.blackboxnlp-1.6",
    pages = "62--79",
    abstract = "Humans can systematically generalize to novel compositions of existing concepts. Recent studies argue that neural networks appear inherently ineffective in such cognitive capacity, leading to a pessimistic view and a lack of attention to optimistic results. We revisit this controversial topic from the perspective of meaningful learning, an exceptional capability of humans to learn novel concepts by connecting them with known ones. We reassess the compositional skills of sequence-to-sequence models conditioned on the semantic links between new and old concepts. Our observations suggest that models can successfully one-shot generalize to novel concepts and compositions through semantic linking, either inductively or deductively. We demonstrate that prior knowledge plays a key role as well. In addition to synthetic tests, we further conduct proof-of-concept experiments in machine translation and semantic parsing, showing the benefits of meaningful learning in applications. We hope our positive findings will encourage excavating modern neural networks{'} potential in systematic generalization through more advanced learning schemes.",
}

@inproceedings{shi-etal-2022-text,
    selected=true, 
    abbr={EMNLP Findings}, 
    arxiv={2210.12276}, 
    url={https://aclanthology.org/2022.findings-emnlp.114/}, 
    pdf={https://aclanthology.org/2022.findings-emnlp.114.pdf}, 
    code={https://github.com/ShiningLab/Text-Editing-as-Imitation-Game}, 
    poster={Text\ Editing\ as\ Imitation\ Game.pdf}, 
    slides={Text\ Editing\ as\ Imitation\ Game.pdf}, 
    title = "Text Editing as Imitation Game",
    author = "Shi, Ning  and
      Tang, Bin  and
      Yuan, Bo  and
      Huang, Longtao  and
      Pu, Yewen  and
      Fu, Jie  and
      Lin, Zhouhan",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2022",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-emnlp.114",
    pages = "1583--1594",
    abstract = "Text editing, such as grammatical error correction, arises naturally from imperfect textual data. Recent works frame text editing as a multi-round sequence tagging task, where operations {--} such as insertion and substitution {--} are represented as a sequence of tags. While achieving good results, this encoding is limited in flexibility as all actions are bound to token-level tags. In this work, we reformulate text editing as an imitation game using behavioral cloning. Specifically, we convert conventional sequence-to-sequence data into state-to-action demonstrations, where the action space can be as flexible as needed. Instead of generating the actions one at a time, we introduce a dual decoders structure to parallel the decoding while retaining the dependencies between action tokens, coupled with trajectory augmentation to alleviate the distribution shift that imitation learning often suffers. In experiments on a suite of Arithmetic Equation benchmarks, our model consistently outperforms the autoregressive baselines in terms of performance, efficiency, and robustness. We hope our findings will shed light on future studies in reinforcement learning applying sequence-level action generation to natural language processing.",
}

@inproceedings{zhang-etal-2022-rochbert,
    selected=false, 
    abbr={EMNLP Findings}, 
    arxiv={2210.15944}, 
    url={https://aclanthology.org/2022.findings-emnlp.256/}, 
    pdf={https://aclanthology.org/2022.findings-emnlp.256.pdf}, 
    code={https://github.com/zzh-z/RoChBERT}, 
    title = "{R}o{C}h{B}ert: Towards Robust {BERT} Fine-tuning for {C}hinese",
    author = "Zhang, Zihan  and
      Li, Jinfeng  and
      Shi, Ning  and
      Yuan, Bo  and
      Liu, Xiangyu  and
      Zhang, Rong  and
      Xue, Hui  and
      Sun, Donghong  and
      Zhang, Chao",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2022",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-emnlp.256",
    pages = "3502--3516",
    abstract = "Despite of the superb performance on a wide range of tasks, pre-trained language models (e.g., BERT) have been proved vulnerable to adversarial texts. In this paper, we present RoChBERT, a framework to build more Robust BERT-based models by utilizing a more comprehensive adversarial graph to fuse Chinese phonetic and glyph features into pre-trained representations during fine-tuning. Inspired by curriculum learning, we further propose to augment the training dataset with adversarial texts in combination with intermediate samples. Extensive experiments demonstrate that RoChBERT outperforms previous methods in significant ways: (i) robust {--} RoChBERT greatly improves the model robustness without sacrificing accuracy on benign texts. Specifically, the defense lowers the success rates of unlimited and limited attacks by 59.43{\%} and 39.33{\%} respectively, while remaining accuracy of 93.30{\%}; (ii) flexible {--} RoChBERT can easily extend to various language models to solve different downstream tasks with excellent performance; and (iii) efficient {--} RoChBERT can be directly applied to the fine-tuning stage without pre-training language model from scratch, and the proposed data augmentation method is also low-cost.",
}

@inproceedings{wang-etal-2021-counterfactual-adversarial,
    selected=false, 
    abbr={EMNLP Findings}, 
    arxiv={2109.04746}, 
    url={https://aclanthology.org/2021.findings-emnlp.413/}, 
    pdf={https://aclanthology.org/2021.findings-emnlp.413.pdf}, 
    code={https://github.com/ShiningLab/CAT}, 
    poster={Counterfactual\ Adversarial\ Learning\ with\ Representation\ Interpolation.pdf}, 
    slides={Counterfactual\ Adversarial\ Learning\ with\ Representation\ Interpolation.pdf}, 
    title = "Counterfactual Adversarial Learning with Representation Interpolation",
    author = "Wang, Wei  and
      Wang, Boxin  and
      Shi, Ning  and
      Li, Jinfeng  and
      Zhu, Bingyu  and
      Liu, Xiangyu  and
      Zhang, Rong",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2021",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-emnlp.413",
    doi = "10.18653/v1/2021.findings-emnlp.413",
    pages = "4809--4820",
    abstract = "Deep learning models exhibit a preference for statistical fitting over logical reasoning. Spurious correlations might be memorized when there exists statistical bias in training data, which severely limits the model performance especially in small data scenarios. In this work, we introduce Counterfactual Adversarial Training framework (CAT) to tackle the problem from a causality perspective. Particularly, for a specific sample, CAT first generates a counterfactual representation through latent space interpolation in an adversarial manner, and then performs Counterfactual Risk Minimization (CRM) on each original-counterfactual pair to adjust sample-wise loss weight dynamically, which encourages the model to explore the true causal effect. Extensive experiments demonstrate that CAT achieves substantial performance improvement over SOTA across different downstream tasks, including sentence classification, natural language inference and question answering.",
}

@inproceedings{shi21_interspeech,
    selected=true, 
    abbr={INTERSPEECH}, 
    arxiv={2106.06731}, 
    pdf={https://www.isca-speech.org/archive/pdfs/interspeech_2021/shi21_interspeech.pdf}, 
    code={https://github.com/ShiningLab/POS-Tagger-for-Punctuation-Restoration}, 
    poster={Incorporating\ External\ POS\ Tagger\ for\ Punctuation\ Restoration.pdf}, 
    slides={Incorporating\ External\ POS\ Tagger\ for\ Punctuation\ Restoration.pdf}, 
    author={Ning Shi and Wei Wang and Boxin Wang and Jinfeng Li and Xiangyu Liu and Zhouhan Lin}, 
    title={{Incorporating External POS Tagger for Punctuation Restoration}}, 
    year=2021, 
    booktitle={Proc. Interspeech 2021}, 
    pages={1987--1991}, 
    url={https://www.isca-speech.org/archive/interspeech_2021/shi21_interspeech.html}, 
    doi={10.21437/Interspeech.2021-1708}, 
    abstract="Punctuation restoration is an important post-processing step in automatic speech recognition. Among other kinds of external information, part-of-speech (POS) taggers provide informative tags, suggesting each input token’s syntactic role, which has been shown to be beneficial for the punctuation restoration task. In this work, we incorporate an external POS tagger and fuse its predicted labels into the existing language model to provide syntactic information. Besides, we propose sequence boundary sampling (SBS) to learn punctuation positions more efficiently as a sequence tagging task. Experimental results show that our methods can consistently obtain performance gains and achieve a new state-of-the-art on the common IWSLT benchmark. Further ablation studies illustrate that both large pre-trained language models and the external POS tagger take essential parts to improve the model’s performance."
}

@inproceedings{shi-etal-2020-recurrent,
    selected=true, 
    abbr={EMNLP Findings}, 
    arxiv={2009.12643}, 
    pdf={https://aclanthology.org/2020.findings-emnlp.159.pdf}, 
    code={https://github.com/ShiningLab/Recurrent-Text-Editing}, 
    poster={Recurrent\ Inference\ in\ Text\ Editing.pdf}, 
    slides={Recurrent\ Inference\ in\ Text\ Editing.pdf}, 
    title = "Recurrent Inference in Text Editing",
    author = "Shi, Ning  and
      Zeng, Ziheng  and
      Zhang, Haotian  and
      Gong, Yichen",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.159",
    doi = "10.18653/v1/2020.findings-emnlp.159",
    pages = "1758--1769",
    abstract = "In neural text editing, prevalent sequence-to-sequence based approaches directly map the unedited text either to the edited text or the editing operations, in which the performance is degraded by the limited source text encoding and long, varying decoding steps. To address this problem, we propose a new inference method, Recurrence, that iteratively performs editing actions, significantly narrowing the problem space. In each iteration, encoding the partially edited text, Recurrence decodes the latent representation, generates an action of short, fixed-length, and applies the action to complete a single edit. For a comprehensive comparison, we introduce three types of text editing tasks: Arithmetic Operators Restoration (AOR), Arithmetic Equation Simplification (AES), Arithmetic Equation Correction (AEC). Extensive experiments on these tasks with varying difficulties demonstrate that Recurrence achieves improvements over conventional inference methods.",
}
